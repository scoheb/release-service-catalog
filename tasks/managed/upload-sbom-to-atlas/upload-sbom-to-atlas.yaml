---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: upload-sbom-to-atlas
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: |-
    This Tekton task gathers SBOM data from a directory specified by the parameters
    and uploads them to Atlas. Supports both CycloneDX and SPDX format. If the push
    to Atlas fails, the SBOM is pushed to an S3 bucket. The push to Atlas is then
    retried asynchronously from the bucket by another service. (Bombino)

    The provided directory is searched for SBOMs recursively and all found SBOMs
    are uploaded as-is to Atlas.

    Optionally, if the dataPath, snapshotSpec and releaseId parameters are
    provided, pushes SBOM regeneration data to the S3 bucket.
  params:
    - name: dataPath
      description: Relative path to the JSON data file in the workspace
      type: string
      default: ""
    - name: snapshotSpec
      type: string
      description: Path to the mapped snapshot spec
      default: ""
    - name: releaseId
      type: string
      description: Release ID to name SBOM regeneration data with
      default: ""
    - name: sbomDir
      description: >-
        Directory containing SBOM files. The task will search for JSON
        SBOMs recursively in this directory and upload them all to Atlas.
        The path is relative to the 'data' workspace
      type: string
    - name: httpRetries
      default: "3"
      description: Maximum number of retries for transient HTTP(S) errors
      type: string
    - name: atlasSecretName
      default: atlas-prod-sso-secret
      description: Name of the Secret containing SSO auth credentials for Atlas
      type: string
    - name: atlasApiUrl
      default: "https://atlas.release.devshift.net"
      description: URL of the Atlas API host
      type: string
    - name: ssoTokenUrl
      default: "https://auth.redhat.com/auth/realms/EmployeeIDP/protocol/openid-connect/token"
      description: URL of the SSO token issuer
      type: string
    - name: ociStorage
      description: The OCI repository where the Trusted Artifacts are stored
      type: string
      default: "empty"
    - name: ociArtifactExpiresAfter
      description: Expiration date for the trusted artifacts created in the
        OCI repository. An empty string means the artifacts do not expire
      type: string
      default: "1d"
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable
      type: string
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: subdirectory
      # subdirectory is only needed for testing purposes
      description: Subdirectory inside the workspace to be used
      type: string
      default: ""
    - name: dataDir
      description: The location where data will be stored
      type: string
      default: $(workspaces.data.path)
    - name: taskGitUrl
      type: string
      description: The url to the git repo where the release-service-catalog tasks and stepactions to be used are stored
    - name: taskGitRevision
      type: string
      description: The revision in the taskGitUrl repo to be used
    - name: retryAWSSecretName
      description: Name of the Secret containing AWS credentials for retry mechanism
    - name: retryS3Bucket
      description: Name of the S3 bucket for the retry mechanism
  workspaces:
    - name: data
  results:
    - description: Produced trusted data artifact
      name: sourceDataArtifact
      type: string
  volumes:
    - name: atlas-secret
      secret:
        secretName: $(params.atlasSecretName)
    - name: aws-secret
      secret:
        secretName: $(params.retryAWSSecretName)
    - name: workdir
      emptyDir: {}
  stepTemplate:
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
    env:
      - name: IMAGE_EXPIRES_AFTER
        value: $(params.ociArtifactExpiresAfter)
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
  steps:
    - name: skip-trusted-artifact-operations
      computeResources:
        limits:
          memory: 32Mi
        requests:
          memory: 32Mi
          cpu: 20m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/skip-trusted-artifact-operations/skip-trusted-artifact-operations.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)
    - name: use-trusted-artifact
      computeResources:
        limits:
          memory: 64Mi
        requests:
          memory: 64Mi
          cpu: 30m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)
    - name: upload-sboms
      image: quay.io/konflux-ci/release-service-utils:e633d51cd41d73e4b3310face21bb980af7a662f
      computeResources:
        limits:
          memory: 32Mi
        requests:
          memory: 32Mi
          cpu: 10m
      volumeMounts:
        - name: atlas-secret
          mountPath: /secrets/
      script: |
        #!/usr/bin/env bash
        set -o errexit -o pipefail -o nounset

        sbomsDir="$(params.dataDir)/$(params.sbomDir)"
        failedSbomDir="$(params.dataDir)/$(params.subdirectory)/failed-sboms"
        # make sure the directory wasn't created in a previous run of this task
        rm -rf "$failedSbomDir"
        mkdir -p "$failedSbomDir"

        shopt -s nullglob
        sboms_to_upload=("$sbomsDir"/*)

        if [[ "${#sboms_to_upload[@]}" -eq 0 ]]; then
          echo "No SBOMs to upload"
          exit 0
        fi

        httpRetries=$(params.httpRetries)
        curl_opts=(--silent --show-error --fail-with-body --retry "$httpRetries")

        sso_account="$(cat /secrets/sso_account)"
        sso_token="$(cat /secrets/sso_token)"

        for sbom_path in "${sboms_to_upload[@]}"; do
          echo "Processing $sbom_path"

          ssoTokenUrl=$(params.ssoTokenUrl)
          echo "Getting SSO token from $ssoTokenUrl"

          token_response="$(
            curl -X POST "${curl_opts[@]}" \
              -d "grant_type=client_credentials" \
              -d "client_id=$sso_account" \
              -d "client_secret=$sso_token" \
              "$ssoTokenUrl"
            )"

          # https://www.rfc-editor.org/rfc/rfc6749.html#section-5.1
          access_token="$(jq -r .access_token <<< "$token_response")"
          expires_in="$(jq -r ".expires_in // empty" <<< "$token_response")"

          retry_max_time=0  # no limit
          if [[ -n "$expires_in" ]]; then
            retry_max_time="$expires_in"
          fi

          atlasApiUrl=$(params.atlasApiUrl)
          echo "Uploading SBOM $sbom_path to $atlasApiUrl"

          handle_atlas_failure () {
            >&2 echo "WARNING: SBOM upload of $1 to Atlas has failed! Upload will be retried later."
            cp "$1" "${failedSbomDir}"
          }

          curl -X POST "${curl_opts[@]}" \
            --retry-max-time "$retry_max_time" \
            -H "authorization: Bearer $access_token" \
            -H "transfer-encoding: chunked" \
            -H "content-type: application/json" \
            --data "@$sbom_path" \
            "$atlasApiUrl/api/v2/sbom" \
            || handle_atlas_failure "$sbom_path"

          # In the stage environment (and e2e tests), retry the push of all
          # SBOMs to test functionality of the retry mechanism.
          if [[ "$(params.atlasSecretName)" = "atlas-staging-sso-secret" ]]; then
            cp "$sbom_path" "${failedSbomDir}"
          fi
        done

    - name: push-to-s3
      image: quay.io/konflux-ci/release-service-utils:e85ceb962ee6f4d0672b4aa4e9946621ab302f20
      computeResources:
        limits:
          memory: 32Mi
        requests:
          memory: 32Mi
          cpu: 10m
      volumeMounts:
        - name: aws-secret
          mountPath: /secrets
      script: |
        #!/usr/bin/env bash
        set -o pipefail -o nounset

        aws_access_key_id="$(cat /secrets/atlas-aws-access-key-id)"
        aws_secret_access_key="$(cat /secrets/atlas-aws-secret-access-key)"

        sbomDir="$(params.dataDir)/$(params.subdirectory)/failed-sboms"
        echo "$(find "$sbomDir" -type f | wc -l) SBOMs to upload to S3."

        region="us-east-1"
        bucket="$(params.retryS3Bucket)"

        shopt -s nullglob
        for sbom in "$sbomDir"/*; do
          # we don't want the full path in S3
          s3_filename=$(basename "$sbom")

          resource="/${bucket}/${s3_filename}"
          content_type="application/json"
          date_value=$(date -R)
          to_sign="PUT\n\n${content_type}\n${date_value}\n${resource}"
          signature=$(echo -en "${to_sign}" | openssl sha1 -hmac "${aws_secret_access_key}" -binary | base64)

          echo "Pushing $sbom to S3."
          if ! curl -X PUT --upload-file "${sbom}" \
              --silent --show-error --fail-with-body --retry 10 \
              --retry-all-errors \
              -H "Host: ${bucket}.s3.${region}.amazonaws.com" \
              -H "Date: ${date_value}" \
              -H "Content-Type: ${content_type}" \
              -H "Authorization: AWS ${aws_access_key_id}:${signature}" \
              "https://${bucket}.s3.${region}.amazonaws.com/${s3_filename}"; then
            >&2 echo "ERROR: Failed to push SBOM to S3 bucket."
            exit 1
          fi
        done

    - name: push-regeneration-data-to-s3
      image: quay.io/konflux-ci/release-service-utils:e85ceb962ee6f4d0672b4aa4e9946621ab302f20
      computeResources:
        limits:
          memory: 32Mi
        requests:
          memory: 32Mi
          cpu: 10m
      volumeMounts:
        - name: aws-secret
          mountPath: /secrets
      script: |
        #!/usr/bin/env bash
        set -o pipefail -o nounset

        if [ -z "$(params.dataPath)" ]; then
          echo "Release data path not provided, skipping regeneration data push."
          exit 0
        fi

        if [ -z "$(params.snapshotSpec)" ]; then
          echo "Snapshot spec path not provided, skipping regeneration data push."
          exit 0
        fi

        if [ -z "$(params.releaseId)" ]; then
          echo "Snapshot spec path not provided, skipping regeneration data push."
          exit 0
        fi

        aws_access_key_id="$(cat /secrets/atlas-aws-access-key-id)"
        aws_secret_access_key="$(cat /secrets/atlas-aws-secret-access-key)"

        region="us-east-1"
        bucket="$(params.retryS3Bucket)"

        push_s3() {
          prefix="$1"
          file="$2"

          s3_filename="${prefix}/$(params.releaseId)"
          resource="/${bucket}/${s3_filename}"

          echo "Pushing $file to $prefix"
          content_type="application/json"
          date_value=$(date -R)
          to_sign="PUT\n\n${content_type}\n${date_value}\n${resource}"
          signature=$(echo -en "${to_sign}" | openssl sha1 -hmac "${aws_secret_access_key}" -binary | base64)

          if ! curl -X PUT --upload-file "$file" \
              --silent --show-error --fail-with-body --retry 10 \
              --retry-all-errors \
              -H "Host: ${bucket}.s3.${region}.amazonaws.com" \
              -H "Date: ${date_value}" \
              -H "Content-Type: ${content_type}" \
              -H "Authorization: AWS ${aws_access_key_id}:${signature}" \
              "https://${bucket}.s3.${region}.amazonaws.com/${s3_filename}"; then
            >&2 echo "ERROR: Failed to push SBOM regeneration data to S3 bucket."
            exit 1
          fi
        }

        data_path="$(params.dataDir)/$(params.dataPath)"
        snapshot_path="$(params.dataDir)/$(params.snapshotSpec)"

        push_s3 "release-data" "$data_path"
        push_s3 "snapshots" "$snapshot_path"

    - name: create-trusted-artifact
      computeResources:
        limits:
          memory: 128Mi
        requests:
          memory: 128Mi
          cpu: 250m
      ref:
        resolver: "git"
        params:
          - name: url
            value: "$(params.taskGitUrl)"
          - name: revision
            value: "$(params.taskGitRevision)"
          - name: pathInRepo
            value: stepactions/create-trusted-artifact/create-trusted-artifact.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
    - name: patch-source-data-artifact-result
      computeResources:
        limits:
          memory: 32Mi
        requests:
          memory: 32Mi
          cpu: 20m
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/patch-source-data-artifact-result/patch-source-data-artifact-result.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
