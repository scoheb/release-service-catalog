---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: push-rpm-data-to-pyxis
  labels:
    app.kubernetes.io/version: "2.0.0"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
    Tekton task that extracts all rpms from the sboms and pushes them to Pyxis as an RPM Manifest.
    In addition, it will also update ContainerImage.content_sets field in Pyxis to include
    all repository_id strings found in rpm purl strings in the sboms.
  params:
    - name: pyxisJsonPath
      description: Path to the JSON string of the saved Pyxis data in the data workspace
      type: string
    - name: pyxisSecret
      type: string
      description: |
        The kubernetes secret to use to authenticate to Pyxis. It needs to contain two keys: key and cert
    - name: server
      type: string
      description: The server type to use. Options are 'production','production-internal,'stage-internal' and 'stage'.
      default: production
    - name: concurrentLimit
      type: string
      description: The maximum number of images to be processed at once
      default: 4
    - name: ociStorage
      description: The OCI repository where the Trusted Artifacts are stored.
      type: string
      default: "empty"
    - name: ociArtifactExpiresAfter
      description: Expiration date for the trusted artifacts created in the
        OCI repository. An empty string means the artifacts do not expire.
      type: string
      default: "1d"
    - name: trustedArtifactsDebug
      description: Flag to enable debug logging in trusted artifacts. Set to a non-empty string to enable.
      type: string
      default: ""
    - name: orasOptions
      description: oras options to pass to Trusted Artifacts calls
      type: string
      default: ""
    - name: sourceDataArtifact
      type: string
      description: Location of trusted artifacts to be used to populate data directory
      default: ""
    - name: subdirectory
      description: Subdirectory inside the workspace to be used
      type: string
      default: ""
    - name: dataDir
      description: The location where data will be stored
      type: string
      default: $(workspaces.data.path)
    - name: taskGitUrl
      type: string
      description: The url to the git repo where the release-service-catalog tasks and stepactions to be used are stored
    - name: taskGitRevision
      type: string
      description: The revision in the taskGitUrl repo to be used
  results:
    - name: sbomPath
      description: |
        Path to a directory that SBOM files are downloaded onto.
    - description: Produced trusted data artifact
      name: sourceDataArtifact
      type: string
  workspaces:
    - name: data
      description: |
        The workspace where the pyxis data json file resides and where sboms will be downloaded to.
  volumes:
    - name: workdir
      emptyDir: {}
  stepTemplate:
    volumeMounts:
      - mountPath: /var/workdir
        name: workdir
    env:
      - name: IMAGE_EXPIRES_AFTER
        value: $(params.ociArtifactExpiresAfter)
      - name: "ORAS_OPTIONS"
        value: "$(params.orasOptions)"
      - name: "DEBUG"
        value: "$(params.trustedArtifactsDebug)"
  steps:
    - name: skip-trusted-artifact-operations
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/skip-trusted-artifact-operations/skip-trusted-artifact-operations.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)/$(params.subdirectory)
    - name: use-trusted-artifact
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/use-trusted-artifact/use-trusted-artifact.yaml
      params:
        - name: workDir
          value: $(params.dataDir)/$(params.subdirectory)
        - name: sourceDataArtifact
          value: $(params.sourceDataArtifact)
    - name: download-sbom-files
      image:
        quay.io/konflux-ci/release-service-utils:863fee5fdf48937dead6a2355c67eb3b4f469340
      script: |
        #!/usr/bin/env bash
        set -eux

        PYXIS_FILE="$(params.dataDir)/$(params.pyxisJsonPath)"
        if [ ! -f "${PYXIS_FILE}" ] ; then
            echo "No valid pyxis file was provided."
            exit 1
        fi

        NUM_COMPONENTS=$(jq '.components | length' "${PYXIS_FILE}")

        SBOM_PATH="$(dirname "$(params.pyxisJsonPath)")/downloaded-sboms"
        # The dir might already exist in case of retries of the task.
        # No need for a cleanup - we will just override the files.
        mkdir -p "$(params.dataDir)/${SBOM_PATH}"
        cd "$(params.dataDir)/${SBOM_PATH}"
        DOCKER_CONFIG="$(mktemp -d)"
        export DOCKER_CONFIG

        for (( i=0; i < NUM_COMPONENTS; i++ )); do
          COMPONENT=$(jq -c --argjson i "$i" '.components[$i]' "${PYXIS_FILE}")
          IMAGEURL=$(jq -r '.containerImage' <<< "${COMPONENT}")
          NUM_PYXIS_IMAGES=$(jq '.pyxisImages | length' <<< "${COMPONENT}")
          # cosign has very limited support for selecting the right auth entry,
          # so create a custom auth file with just one entry
          select-oci-auth "$IMAGEURL" > "$DOCKER_CONFIG"/config.json
          for (( j=0; j < NUM_PYXIS_IMAGES; j++ )); do
            PYXIS_IMAGE=$(jq -c --argjson j "$j" '.pyxisImages[$j]' <<< "${COMPONENT}")
            FILE="$(jq -r '.imageId' <<< "$PYXIS_IMAGE").json"
            DIGEST="$(jq -r '.digest' <<< "$PYXIS_IMAGE")"
            ARCH_DIGEST="$(jq -r '.arch_digest' <<< "$PYXIS_IMAGE")"
            # You can't pass --platform to a single arch image or cosign errors.
            # If digest equals arch_digest, then it's a single arch image
            if [ "$DIGEST" = "$ARCH_DIGEST" ] ; then
              echo "Fetching sbom for single arch image: $IMAGEURL to: $FILE"
              cosign download sbom --output-file "${FILE}" "${IMAGEURL}"
            else
              OS=$(jq -r '.os' <<< "$PYXIS_IMAGE")
              ARCH=$(jq -r '.arch' <<< "$PYXIS_IMAGE")
              PLATFORM="${OS}/${ARCH}"
              echo "Fetching sbom for image: $IMAGEURL with platform: $PLATFORM to: $FILE"
              cosign download sbom --output-file "${FILE}" --platform "${PLATFORM}" "${IMAGEURL}"
            fi
          done
        done

        sbom_files=(*.json)
        SBOM_COUNT=${#sbom_files[@]}
        PYXIS_IMAGES=$(jq '[.components[].pyxisImages | length] | add' "${PYXIS_FILE}")
        if [ "$SBOM_COUNT" != "$PYXIS_IMAGES" ]; then
          echo "ERROR: Expected to fetch sbom for $PYXIS_IMAGES images, but only $SBOM_COUNT were saved"
          exit 1
        fi

        echo -n "${SBOM_PATH}" > "$(results.sbomPath.path)"

    - name: push-rpm-data-to-pyxis
      image:
        quay.io/konflux-ci/release-service-utils:863fee5fdf48937dead6a2355c67eb3b4f469340
      env:
        - name: PYXIS_CERT
          valueFrom:
            secretKeyRef:
              name: $(params.pyxisSecret)
              key: cert
        - name: PYXIS_KEY
          valueFrom:
            secretKeyRef:
              name: $(params.pyxisSecret)
              key: key
      script: |
        #!/usr/bin/env bash
        set -eu

        if [[ "$(params.server)" == "production" ]]
        then
          export PYXIS_GRAPHQL_API="https://graphql-pyxis.api.redhat.com/graphql/"
        elif [[ "$(params.server)" == "stage" ]]
        then
          export PYXIS_GRAPHQL_API="https://graphql-pyxis.preprod.api.redhat.com/graphql/"
        elif [[ "$(params.server)" == "production-internal" ]]
        then
          export PYXIS_GRAPHQL_API="https://graphql.pyxis.engineering.redhat.com/graphql/"
        elif [[ "$(params.server)" == "stage-internal" ]]
        then
          export PYXIS_GRAPHQL_API="https://graphql.pyxis.stage.engineering.redhat.com/graphql/"
        else
          echo "Invalid server parameter. Only 'production','production-internal,'stage-internal' and 'stage' allowed."
          exit 1
        fi

        export PYXIS_CERT_PATH=/tmp/crt
        export PYXIS_KEY_PATH=/tmp/key
        echo "${PYXIS_CERT}" > $PYXIS_CERT_PATH
        echo "${PYXIS_KEY}" > $PYXIS_KEY_PATH

        SBOM_PATH="$(dirname "$(params.pyxisJsonPath)")/downloaded-sboms"
        cd "$(params.dataDir)/${SBOM_PATH}"

        N=$(params.concurrentLimit)  # The maximum number of images to be processed at once
        declare -a jobs=()
        json_files=(*.json)
        total=${#json_files[@]}
        count=0
        success=true
        echo "Starting RPM data upload for $total files in total. " \
          "Up to $N files will be uploaded at once..."

        for FILE in *.json; do
          IMAGEID=$(echo "$FILE" | cut -d '.' -f 1)

          # Extract the format information using jq
          UPLOAD_SCRIPT=$(
            jq -r '
              if .bomFormat == "CycloneDX" then
                "upload_rpm_data_cyclonedx"
              else if .spdxVersion then
                "upload_rpm_data"
              else
                empty
              end end' "$FILE"
          )

          # If UPLOAD_SCRIPT is empty, it's not a valid SBOM (CycloneDX or SPDX)
          if [ -z "$UPLOAD_SCRIPT" ]; then
            echo "Error: ${FILE}: not a valid SBOM (CycloneDX or SPDX)"
            exit 1
          fi

          echo Uploading RPM data to Pyxis for IMAGE: "$IMAGEID" with SBOM: "$FILE using script: $UPLOAD_SCRIPT"
          $UPLOAD_SCRIPT --retry --image-id "$IMAGEID" --sbom-path "$FILE" --verbose > "${IMAGEID}.out" 2>&1 &

          jobs+=($!)  # Save the background process ID
          images+=("$IMAGEID")
          ((++count))

          if [ $((count%N)) -eq 0 ] || [ $((count)) -eq "$total" ]; then
            echo Waiting for the current batch of background processes to finish
            for job_id in "${!jobs[@]}"; do
              if ! wait "${jobs[job_id]}"; then
                echo "Error: upload of rpm data failed for one of the images"
                success=false
              fi
            done

            echo
            echo Printing outputs for current upload_rpm_data script runs
            for img in "${images[@]}"; do
              echo "=== $img ==="
              cat "${img}.out"
              echo
            done

            if [ $success != "true" ]; then
              echo ERROR: At least one upload in the last batch failed
              exit 1
            fi

            # Reset job and files arrays for the next batch
            jobs=()
            images=()
          fi
        done
    - name: create-trusted-artifact
      ref:
        resolver: "git"
        params:
          - name: url
            value: "$(params.taskGitUrl)"
          - name: revision
            value: "$(params.taskGitRevision)"
          - name: pathInRepo
            value: stepactions/create-trusted-artifact/create-trusted-artifact.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: workDir
          value: $(params.dataDir)/$(params.subdirectory)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
    - name: patch-source-data-artifact-result
      ref:
        resolver: "git"
        params:
          - name: url
            value: $(params.taskGitUrl)
          - name: revision
            value: $(params.taskGitRevision)
          - name: pathInRepo
            value: stepactions/patch-source-data-artifact-result/patch-source-data-artifact-result.yaml
      params:
        - name: ociStorage
          value: $(params.ociStorage)
        - name: sourceDataArtifact
          value: $(results.sourceDataArtifact.path)
